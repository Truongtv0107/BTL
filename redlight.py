import sys
from PyQt6.QtWidgets import QDialog, QVBoxLayout, QPushButton, QLabel, QFileDialog
from ultralytics import YOLO
import cv2
import os
import tkinter as tk
import numpy as np

# ==============================================================================
# TH√îNG S·ªê C·ªê ƒê·ªäNH V√Ä ROI ƒê√àN ƒê√É C·∫¨P NH·∫¨T
# ==============================================================================
TARGET_W, TARGET_H = 1280, 720  # K√≠ch th∆∞·ªõc chu·∫©n h√≥a video

# ‚ö†Ô∏è T·ªåA ƒê·ªò ROI ƒê√àN ƒê√É C·∫¨P NH·∫¨T (Xung quanh c√°c ƒëi·ªÉm b·∫°n cung c·∫•p)
# ƒê√®n b√™n tr√°i: Trung t√¢m ~ (21, 108). Ch·ªçn v√πng 30x70 pixel xung quanh.
# ROI [x1, y1, x2, y2]
ROI_LIGHT_LEFT = (21 - 15, 108 - 35, 21 + 15, 108 + 35) # (6, 73, 36, 143)

# ƒê√®n b√™n ph·∫£i: Trung t√¢m ~ (1261, 98). Ch·ªçn v√πng 30x70 pixel xung quanh.
ROI_LIGHT_RIGHT = (1261 - 15, 98 - 35, 1261 + 15, 98 + 35) # (1246, 63, 1276, 133)
# C·∫ßn ƒë·∫£m b·∫£o x2 kh√¥ng v∆∞·ª£t qu√° 1280
ROI_LIGHT_RIGHT = (1246, 63, 1279, 133) 


def get_screen_size():
    """L·∫•y k√≠ch th∆∞·ªõc m√†n h√¨nh ch√≠nh"""
    root = tk.Tk()
    root.withdraw()
    return root.winfo_screenwidth(), root.winfo_screenheight()


class RedLightDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("üö¶ Nh·∫≠n Di·ªán ƒê√®n Giao Th√¥ng")
        self.setFixedSize(600, 300)

        screen_w, screen_h = get_screen_size()
        self.move((screen_w - self.width()) // 2, (screen_h - self.height()) // 2)

        layout = QVBoxLayout()
        self.label = QLabel("Ch·ª©c nƒÉng ch·ªâ nh·∫≠n di·ªán v√† hi·ªÉn th·ªã tr·∫°ng th√°i ƒë√®n.")
        self.btn_start = QPushButton("‚ñ∂ B·∫Øt ƒë·∫ßu (Camera)")
        self.btn_video = QPushButton("üìÇ Ch·ªçn video")
        self.btn_stop = QPushButton("‚èπ D·ª´ng")
        
        layout.addWidget(self.label)
        layout.addWidget(self.btn_start)
        layout.addWidget(self.btn_video)
        layout.addWidget(self.btn_stop)
        
        self.setLayout(layout)

        # Load YOLO model
        self.model = YOLO("yolov8n.pt")

        # Tr·∫°ng th√°i
        self.running = False
        self.light_state_left = "UNKNOWN"
        self.light_state_right = "UNKNOWN"
        
        self.btn_start.clicked.connect(self.start_detect_camera)
        self.btn_video.clicked.connect(self.start_detect_video)
        self.btn_stop.clicked.connect(self.stop_detect)
        
        self.update_status_label()

    def get_light_color_from_roi(self, roi):
        """X√°c ƒë·ªãnh m√†u c·ªßa v√πng ROI ƒë√®n giao th√¥ng d·ª±a tr√™n gi√° tr·ªã BGR trung b√¨nh"""
        if roi is None or roi.size == 0:
            return "UNKNOWN"
        
        b, g, r = roi.mean(axis=(0, 1))
        
        if r > g * 1.5 and r > 80:
            return "RED"
        elif g > r * 1.5 and g > 80:
            return "GREEN"
        elif r > 100 and g > 100 and abs(r - g) < 60:
            return "YELLOW"
        else:
            return "UNKNOWN"

    def update_status_label(self):
        """C·∫≠p nh·∫≠t tr·∫°ng th√°i ƒë√®n tr√™n c·ª≠a s·ªï PyQt"""
        text = (f"Tr·∫°ng th√°i ƒê√®n Tr√°i: **{self.light_state_left}**\n"
                f"Tr·∫°ng th√°i ƒê√®n Ph·∫£i: **{self.light_state_right}**\n\n"
                f"Ch·ªçn ngu·ªìn ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán.")
        self.label.setText(text)

    def detect(self, cap):
        if not cap.isOpened():
            self.label.setText("‚ùå L·ªói: Kh√¥ng th·ªÉ m·ªü video/camera")
            return

        screen_w, screen_h = get_screen_size()
        self.running = True

        while self.running:
            ret, frame = cap.read()
            if not ret:
                break

            # 1. Chu·∫©n h√≥a k√≠ch th∆∞·ªõc khung h√¨nh
            frame = cv2.resize(frame, (TARGET_W, TARGET_H))
            frame_h, frame_w = frame.shape[:2]

            # 2. L·∫•y ROI v√† X√°c ƒë·ªãnh m√†u ƒë√®n (CH·ªà S·ª¨ D·ª§NG C√ÅC ROI C·ªê ƒê·ªäNH)
            
            # ƒê√®n Tr√°i
            x1_l, y1_l, x2_l, y2_l = ROI_LIGHT_LEFT
            roi_l = frame[y1_l:y2_l, x1_l:x2_l]
            self.light_state_left = self.get_light_color_from_roi(roi_l)
            
            # ƒê√®n Ph·∫£i
            x1_r, y1_r, x2_r, y2_r = ROI_LIGHT_RIGHT
            roi_r = frame[y1_r:y2_r, x1_r:x2_r]
            self.light_state_right = self.get_light_color_from_roi(roi_r)

            # 3. V·∫Ω khung ROI v√† Label l√™n khung h√¨nh (d√πng m√†u cho d·ªÖ debug)
            color_map = {"RED": (0, 0, 255), "GREEN": (0, 255, 0), "YELLOW": (0, 255, 255), "UNKNOWN": (100, 100, 100)}
            
            # V·∫Ω ƒë√®n Tr√°i
            color_l = color_map.get(self.light_state_left)
            cv2.rectangle(frame, (x1_l, y1_l), (x2_l, y2_l), color_l, 2)
            cv2.putText(frame, f"LEFT: {self.light_state_left}", (x1_l, y1_l - 5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_l, 2)

            # V·∫Ω ƒë√®n Ph·∫£i
            color_r = color_map.get(self.light_state_right)
            cv2.rectangle(frame, (x1_r, y1_r), (x2_r, y2_r), color_r, 2)
            cv2.putText(frame, f"RIGHT: {self.light_state_right}", (x1_r - 50, y1_r - 5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_r, 2)


            # 4. Nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng kh√°c b·∫±ng YOLO (nh∆∞ng kh√¥ng x·ª≠ l√Ω vi ph·∫°m)
            results = self.model(frame, verbose=False)
            
            # 5. C·∫≠p nh·∫≠t tr·∫°ng th√°i tr√™n dialog
            self.update_status_label()

            # 6. Hi·ªÉn th·ªã video
            cv2.imshow("Traffic Light Detection", frame)

            # ƒêi·ªÅu ch·ªânh c·ª≠a s·ªï theo k√≠ch th∆∞·ªõc m√†n h√¨nh
            win_w, win_h = frame_w, frame_h
            if win_w > screen_w or win_h > screen_h:
                 scale = min(screen_w / win_w, screen_h / win_h) * 0.7 
                 win_w, win_h = int(win_w * scale), int(win_h * scale)
            cv2.resizeWindow("Traffic Light Detection", win_w, win_h)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
        self.running = False
        self.light_state_left = "Stopped"
        self.light_state_right = "Stopped"
        self.update_status_label()

    def start_detect_camera(self):
        if not self.running:
            cap = cv2.VideoCapture(0)
            self.detect(cap)

    def start_detect_video(self):
        if not self.running:
            file_path, _ = QFileDialog.getOpenFileName(
                self, "Ch·ªçn video", "", "Video Files (*.mp4 *.avi *.mov)"
            )
            if file_path and os.path.exists(file_path):
                cap = cv2.VideoCapture(file_path)
                self.detect(cap)

    def stop_detect(self):
        self.running = False
        self.light_state_left = "Stopped"
        self.light_state_right = "Stopped"
        self.update_status_label()